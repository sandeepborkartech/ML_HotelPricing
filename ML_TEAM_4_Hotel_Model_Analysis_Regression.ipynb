{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "> This data set contains booking information for a city hotel and a resort hotel, and includes information such as when the booking was made, length of stay, the number of adults, children, and/or babies, and the number of available parking spaces, among other things.\n",
    "\n",
    "> Our analysis will try to answer questions of how duration between booking and reservation and other factors affect reservation price. Further questions of price analysis will also be performed to find optimum independent parameters to find minimum dependent variable value, in this case, the booking price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "important commands\n",
    "> - Shift + Enter (executes cell)\n",
    "> - Alt + Enter (executes and creates new cell)\n",
    "> - Esc + Shift + Up/Down (expands selection)\n",
    "> - Up/Down (moves cells up/down)\n",
    "\n",
    "> Esc + M (converts cell to markup)\n",
    "> Esc + Y (converts cell to code)\n",
    "> Esc + H (shows all commands)\n",
    "\n",
    "> Underscore twice (converts to bold)\n",
    "> Astrisk once (convrets to italics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis\n",
    "\n",
    "Apply model analysis to prepared data from Data Prep notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = AdaBoostRegressor()\\nmodel.fit(X_train_norm_filtered, y_train)\\n\\nmodel = ElasticNet(alpha=1.0, tol=0.0001)\\nmodel.fit(X_train_norm_filtered, y_train)\\n\\n\\nmodel = RandomForestRegressor()\\nmodel.fit(X_train_norm_filtered, y_train)\\n\\nmodel = SGDRegressor(max_iter=10000, tol=1e-3, eta0 = 0.0001)\\nmodel.fit(X_train_norm_filtered, y_train)\\n\\n\\nmodel = LinearRegression()\\nmodel.fit(X_train_norm_filtered, y_train)\\n\\n\\n\\nmodel = linear_model.LassoLars(alpha=0.00001)\\nmodel.fit(X_train_norm_filtered, y_train)\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm_reg_kbest = pd.read_pickle('X_train_norm_reg_kbest.pkl')\n",
    "X_test_norm_reg_kbest = pd.read_pickle('X_test_norm_reg_kbest.pkl')\n",
    "y_train_reg = pd.read_pickle('y_train_reg.pkl')\n",
    "y_test_reg = pd.read_pickle('y_test_reg.pkl')\n",
    "\n",
    "model = SGDRegressor()\n",
    "model.fit(X_train_norm_reg_kbest, y_train_reg)\n",
    "\n",
    "\"\"\"\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(X_train_norm_filtered, y_train)\n",
    "\n",
    "model = ElasticNet(alpha=1.0, tol=0.0001)\n",
    "model.fit(X_train_norm_filtered, y_train)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train_norm_filtered, y_train)\n",
    "\n",
    "model = SGDRegressor(max_iter=10000, tol=1e-3, eta0 = 0.0001)\n",
    "model.fit(X_train_norm_filtered, y_train)\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_norm_filtered, y_train)\n",
    "\n",
    "\n",
    "\n",
    "model = linear_model.LassoLars(alpha=0.00001)\n",
    "model.fit(X_train_norm_filtered, y_train)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-Search CV\n",
    "Performing GridSearchCV on each regression model in a loop to discover their best parameters and scores __RMSE__, __MAE__. These scores will be used to determine which one is the best performing model for price prediction (__adr__)\n",
    "We explore the following regression models:\n",
    "> - __Linear Regression__\n",
    "> - __Stochastic Gradient Descent Regression__\n",
    "> - __Elastic Net__\n",
    "> - __SVR__\n",
    "> - __Ada Boost Regression__\n",
    "> - __Gradient Boost Regression__\n",
    "> - __Random Forest Regression__\n",
    "> - __K Neighbors Regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assisting functions for GridSearch\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "##----------------------------------##\n",
    "def perform_grid_search(model, param_grid, X_train, X_test, y_train):\n",
    "    \n",
    "    grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 3)\n",
    "    \n",
    "    best_model = grid.fit(X_train, y_train)\n",
    "    print('##----------------------------##')\n",
    "    print('Model: ', best_model.estimator)\n",
    "    print('Best Parameters: ', best_model.best_params_)\n",
    "    \n",
    "    y_predict = best_model.predict(X_test)\n",
    "\n",
    "    return y_predict\n",
    "\n",
    "def show_regression_scores(y_test, y_predict):\n",
    "    \n",
    "    mse = np.sqrt(mean_squared_error(y_test.values, y_predict))\n",
    "    mae = mean_absolute_error(y_test.values, y_predict)\n",
    "    \n",
    "    print(\"RMSE\", rmse)\n",
    "    print(\"MAE\", mae)\n",
    "    \n",
    "    return (rmse, mae)\n",
    "\n",
    "def show_classification_scores( y_test, y_predict):\n",
    "    \n",
    "    conf = confusion_matrix( y_test, y_predict)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    precision = precision_score(y_test, y_predict)\n",
    "    recall = recall_score(y_test, y_predict)\n",
    "    \n",
    "    print(\"Confusion Matrix: \", conf)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "##--------------------------------------------##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SGDRegressor'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgdr = SGDRegressor(max_iter=10, tol=1e-3, penalty=\"l2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##----------------------------##\n",
      "Model:  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "Best Parameters:  {}\n",
      "RMSE 27.629898894528445\n",
      "MAE 20.400134907909642\n",
      "##----------------------------##\n",
      "Model:  SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=10,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "Best Parameters:  {'max_iter': 150, 'penalty': 'elasticnet', 'tol': -inf}\n",
      "RMSE 27.629898894528445\n",
      "MAE 20.457723126991265\n",
      "##----------------------------##\n",
      "Model:  ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.0, max_iter=1,\n",
      "           normalize=False, positive=False, precompute=False, random_state=None,\n",
      "           selection='cyclic', tol=0.0001, warm_start=False)\n",
      "Best Parameters:  {'alpha': 0.001, 'l1_ratio': 0.9, 'max_iter': 10}\n",
      "RMSE 27.629898894528445\n",
      "MAE 20.454570466094772\n",
      "##----------------------------##\n",
      "Model:  KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                    weights='uniform')\n",
      "Best Parameters:  {'n_neighbors': 6}\n",
      "RMSE 27.629898894528445\n",
      "MAE 13.167342552068785\n",
      "##----------------------------##\n",
      "Model:  AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse',\n",
      "                                                       max_depth=None,\n",
      "                                                       max_features=None,\n",
      "                                                       max_leaf_nodes=None,\n",
      "                                                       min_impurity_decrease=0.0,\n",
      "                                                       min_impurity_split=None,\n",
      "                                                       min_samples_leaf=1,\n",
      "                                                       min_samples_split=2,\n",
      "                                                       min_weight_fraction_leaf=0.0,\n",
      "                                                       presort=False,\n",
      "                                                       random_state=None,\n",
      "                                                       splitter='best'),\n",
      "                  learning_rate=1.0, loss='linear', n_estimators=50,\n",
      "                  random_state=42)\n",
      "Best Parameters:  {'base_estimator__max_depth': 2, 'n_estimators': 1}\n",
      "RMSE 27.629898894528445\n",
      "MAE 28.855419820841412\n",
      "##----------------------------##\n",
      "Model:  RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=None,\n",
      "                      oob_score=False, random_state=42, verbose=0,\n",
      "                      warm_start=False)\n",
      "Best Parameters:  {'criterion': 'mse', 'n_estimators': 4}\n",
      "RMSE 27.629898894528445\n",
      "MAE 22.742183615430726\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>27.629899</td>\n",
       "      <td>20.400135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>27.629899</td>\n",
       "      <td>20.457723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>27.629899</td>\n",
       "      <td>20.454570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>27.629899</td>\n",
       "      <td>13.167343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>27.629899</td>\n",
       "      <td>28.855420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>27.629899</td>\n",
       "      <td>22.742184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            RMSE        MAE\n",
       "LinearRegression       27.629899  20.400135\n",
       "SGDRegressor           27.629899  20.457723\n",
       "ElasticNet             27.629899  20.454570\n",
       "KNeighborsRegressor    27.629899  13.167343\n",
       "AdaBoostRegressor      27.629899  28.855420\n",
       "RandomForestRegressor  27.629899  22.742184"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "\"\"\"\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr_params = {}\n",
    "criterion = [\"mse\", \"mae\"]\n",
    "\n",
    "# SGDRegressor\n",
    "sgdr = SGDRegressor(max_iter=10, tol=1e-3, penalty=\"l2\")\n",
    "sgdr_params = {\"max_iter\": [50, 100, 150], \"tol\": [1e-1, 1e03, -np.infty], \"penalty\": [\"l2\", \"l1\", \"elasticnet\"]}\n",
    "\n",
    "# DecisionTreeRegressor\n",
    "dcr = DecisionTreeRegressor(random_state=42, min_samples_leaf=10)\n",
    "dcr_params = {\"criterion\": criterion, \"min_samples_split\": [10, 20, 30], \"max_depth\": [2, 4, 6], \"min_samples_leaf\": [10, 20, 30], \"max_leaf_nodes\": [20, 30, 40] }\n",
    "\n",
    "# ElasticNet\n",
    "en = ElasticNet(max_iter = 1, alpha = 1, l1_ratio = 0.0)    \n",
    "en_params = {\"max_iter\": [1, 5, 10], \"alpha\": [0.001, 0.01, 0.1, 1], \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}\n",
    "\n",
    "# SVR\n",
    "svr = SVR(kernel = 'rbf', gamma = 0.1)\n",
    "svr_params = {\"C\": [1e0, 1e1, 1e2, 1e3], \"gamma\": np.logspace(-2, 2, 5)}\n",
    "\n",
    "# KNeighborsRegressor\n",
    "knr = KNeighborsRegressor(n_neighbors=3)\n",
    "knr_params = { \"n_neighbors\": [3,6,9,12]}\n",
    "\n",
    "# AdaBoostRegressor\n",
    "abr = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), random_state=42)\n",
    "abr_params = {\"n_estimators\": (1, 2), \"base_estimator__max_depth\": (1, 2)}\n",
    "\n",
    "# GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor(max_depth = 2, warm_start = True, random_state = 42, n_estimators = 12, learning_rate = 0.1)\n",
    "gbr_params = {\"criterion\": criterion, \"max_depth\": [2,4,6]}\n",
    "\n",
    "# RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators = 1, bootstrap = True, max_depth = 5, random_state = 42)\n",
    "rfr_params = {\"criterion\": criterion, \"n_estimators\": [2,3,4]}\n",
    "\n",
    "# Put all models in an array with their related model to make predictions\n",
    "model_tups = [(lr, lr_params), (sgdr, sgdr_params), (en, en_params), \n",
    "              (knr, knr_params), (abr, abr_params), (rfr, rfr_params)]\n",
    "\n",
    "df_results = pd.DataFrame(columns = [\"RMSE\", \"MAE\"])\n",
    "\n",
    "for model_tup in model_tups:\n",
    "    \n",
    "    model_name = type(model_tup[0]).__name__\n",
    "    \n",
    "    y_predict = perform_grid_search(model_tup[0], model_tup[1], X_train_norm_reg_kbest, X_test_norm_reg_kbest, y_train_reg)\n",
    "\n",
    "    result = show_regression_scores(y_test_reg, y_predict)\n",
    "    \n",
    "    sresult = pd.Series({\"RMSE\": result[0], \"MAE\": result[1]}, name= model_name)\n",
    "\n",
    "    df_results = df_results.append(sresult)\n",
    "\n",
    "df_results\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_pickle(\"df_regression_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>27.629899</td>\n",
       "      <td>20.400135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>27.629899</td>\n",
       "      <td>20.457723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>27.629899</td>\n",
       "      <td>20.454570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>27.629899</td>\n",
       "      <td>13.167343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>27.629899</td>\n",
       "      <td>28.855420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>27.629899</td>\n",
       "      <td>22.742184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            RMSE        MAE\n",
       "LinearRegression       27.629899  20.400135\n",
       "SGDRegressor           27.629899  20.457723\n",
       "ElasticNet             27.629899  20.454570\n",
       "KNeighborsRegressor    27.629899  13.167343\n",
       "AdaBoostRegressor      27.629899  28.855420\n",
       "RandomForestRegressor  27.629899  22.742184"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regression_results = pd.read_pickle(\"df_regression_results.pkl\")\n",
    "df_regression_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.629898894528445\n",
      "20.37776982385659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nlinear\\n29.754990878612507\\n23.252648836567797\\n\\nSVR\\n27.881752005199903\\n20.679435892922054\\n\\nSGD\\n27.441660441583327\\n20.40611646701147\\n\\nRandomForest:\\n27.690988051757227\\n20.529304934191707\\n\\nElastic-Net\\n36.611635396396146\\n28.50927781873622\\n\\nAdaBoost\\n35.36260456131857\\n28.16338324191093\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_test_reg.values, y_hat)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "mae = mean_absolute_error(y_test_reg.values, y_hat)\n",
    "                          \n",
    "print(rmse)\n",
    "print(mae)\n",
    "\n",
    "\"\"\"\n",
    "linear\n",
    "29.754990878612507\n",
    "23.252648836567797\n",
    "\n",
    "SVR\n",
    "27.881752005199903\n",
    "20.679435892922054\n",
    "\n",
    "SGD\n",
    "27.441660441583327\n",
    "20.40611646701147\n",
    "\n",
    "RandomForest:\n",
    "27.690988051757227\n",
    "20.529304934191707\n",
    "\n",
    "Elastic-Net\n",
    "36.611635396396146\n",
    "28.50927781873622\n",
    "\n",
    "AdaBoost\n",
    "35.36260456131857\n",
    "28.16338324191093\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n>>> from sklearn.linear_model import RidgeCV, LassoCV\\n>>> from sklearn.svm import SVR\\n>>> estimators = [('ridge', RidgeCV()),\\n...               ('lasso', LassoCV(random_state=42)),\\n...               ('svr', SVR(C=1, gamma=1e-6))]\\n\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "vg = VotingRegressor(estimators=[('rf', rf), ('lr', lr)])\n",
    "\n",
    "params = { \n",
    "          'rf__n_estimators': [1, 2]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=vg, param_grid=params, cv=2)\n",
    "\n",
    "best_model = grid.fit(X_train_norm_reg_kbest, y_train_reg)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "param_grid = [{\n",
    "        #\"kpca__kernel\": [\"rbf\", \"sigmoid\"]\n",
    "    }]\n",
    "\n",
    "reg_pip = Pipeline([\n",
    "         (\"rf\", rf), (\"vg\", vg)\n",
    "    ])\n",
    "\"\"\"\n",
    "#reg_pip.fit(X_train_norm_reg_kbest, y_train_reg)\n",
    "\n",
    "#reg_pip.get_params()\n",
    "\n",
    "\"\"\"\n",
    ">>> from sklearn.linear_model import RidgeCV, LassoCV\n",
    ">>> from sklearn.svm import SVR\n",
    ">>> estimators = [('ridge', RidgeCV()),\n",
    "...               ('lasso', LassoCV(random_state=42)),\n",
    "...               ('svr', SVR(C=1, gamma=1e-6))]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=VotingRegressor(estimators=[('rf',\n",
       "                                                    RandomForestRegressor(bootstrap=True,\n",
       "                                                                          criterion='mse',\n",
       "                                                                          max_depth=None,\n",
       "                                                                          max_features='auto',\n",
       "                                                                          max_leaf_nodes=None,\n",
       "                                                                          min_impurity_decrease=0.0,\n",
       "                                                                          min_impurity_split=None,\n",
       "                                                                          min_samples_leaf=1,\n",
       "                                                                          min_samples_split=2,\n",
       "                                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                                          n_estimators='warn',\n",
       "                                                                          n_jobs=None,\n",
       "                                                                          oob_score=False,\n",
       "                                                                          random_state=42,\n",
       "                                                                          verbose=0,\n",
       "                                                                          warm_start=False)),\n",
       "                                                   ('lr',\n",
       "                                                    LinearRegression(copy_X=True,\n",
       "                                                                     fit_intercept=True,\n",
       "                                                                     n_jobs=None,\n",
       "                                                                     normalize=False))],\n",
       "                                       n_jobs=None, weights=None),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'rf__n_estimators': [1, 10, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-104-d9426856e61d>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-104-d9426856e61d>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    param_grid = param_grid\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators = 1)\n",
    "vg = VotingRegressor(estimators=[('rf', rf), ('lr', lr)])\n",
    "\n",
    "param_grid = [{\n",
    "        \"kpca__gamma\": np.linspace(0.03, 0.05, 10),\n",
    "        \"kpca__kernel\": [\"rbf\", \"sigmoid\"],\n",
    "        \"kpca__n_components\": [50,55,60,65,70]\n",
    "    }]\n",
    "\n",
    "reg_pip = Pipeline([\n",
    "    (\"kpca\", KernelPCA(n_components=2)),\n",
    "    (\"vg\", vg),\n",
    "    param_grid = param_grid\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\"\"\"\n",
    "model = ElasticNet(alpha=1.0, tol=0.0001)\n",
    "model.fit(X_train_norm_filtered, y_train)\n",
    "\n",
    "model = SGDRegressor(max_iter=10000, tol=1e-3, eta0 = 0.0001)\n",
    "model.fit(X_train_norm_filtered, y_train)\n",
    "\"\"\"\n",
    "# Just initialize the pipeline with any estimator you like    \n",
    "pipe = Pipeline(steps=[('estimator', ElasticNet())])\n",
    "\n",
    "# Add a dict of estimator and estimator related parameters in this list\n",
    "params_grid = [{'estimator': [LinearRegression()]},\n",
    "               {\n",
    "                'estimator':[ElasticNet()],\n",
    "                'estimator__alpha': [0.5, 1, 1.5, 1000],\n",
    "                'estimator__tol': [0.1, 0.001, 0.0001]\n",
    "                },\n",
    "                {\n",
    "                'estimator': [SGDRegressor()],\n",
    "                'estimator__max_iter': [1,2,3,4,5],\n",
    "                'estimator__tol': [1e-1,1e-2,1e-3],\n",
    "                'estimator__eta0': [0.01, 0.001, 0.0001]\n",
    "                },\n",
    "               {'estimator': [RandomForestRegressor()]}\n",
    "               # {'estimator':[Any_other_estimator_you_want],\n",
    "               #  'estimator__valid_param_of_your_estimator':[valid_values]\n",
    "\n",
    "              ]\n",
    "\n",
    "grid = GridSearchCV(pipe, params_grid)\n",
    "out = grid.fit(X_train_norm_reg_kbest, y_train_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)}\n"
     ]
    }
   ],
   "source": [
    "print(out.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# is_cancelled Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118260    0\n",
       "40600     1\n",
       "78329     0\n",
       "62276     1\n",
       "81700     0\n",
       "Name: is_canceled, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "X_train_norm_clf_pca = pd.read_pickle('X_train_norm_clf_pca.pkl')\n",
    "X_test_norm_clf_pca = pd.read_pickle('X_test_norm_clf_pca.pkl')\n",
    "y_train_clf = pd.read_pickle('y_train_clf.pkl')\n",
    "y_test_clf = pd.read_pickle('y_test_clf.pkl')\n",
    "X_train_norm_clf_pca.head()\n",
    "\n",
    "y_test_clf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azizf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "logreg = RandomForestClassifier()\n",
    "logreg.fit(X_train_norm_clf_pca, y_train_clf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18870,  1332],\n",
       "       [ 3464,  8551]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test_norm_clf_pca)\n",
    "type(y_pred)\n",
    "confusion_matrix( y_test_clf, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  :  0.8511344942111307\n",
      "Precision :  0.8652231103915815\n",
      "Recall :  0.7116937161880982\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy  : \", accuracy_score(y_test_clf, y_pred))\n",
    "print(\"Precision : \", precision_score(y_test_clf, y_pred))\n",
    "print(\"Recall : \", recall_score(y_test_clf, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
